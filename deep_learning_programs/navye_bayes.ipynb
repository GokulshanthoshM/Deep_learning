{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMwuR10oqY8HKQ8jfa2wBRe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uYJOFc9WNw8G","executionInfo":{"status":"ok","timestamp":1694670363846,"user_tz":-330,"elapsed":6958,"user":{"displayName":"Gokul Shanthosh","userId":"03657416323634609159"}},"outputId":"7bd7fb9c-5566-44aa-ba4d-42a0ee46bb32"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[[13  0  0]\n"," [ 0 16  0]\n"," [ 0  0  9]]\n"]},{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{},"execution_count":4}],"source":["import numpy as np\n","import pandas as pd\n","from google.colab import drive\n","drive.mount('/content/drive')\n","#Importing the dataset\n","\"\"\"\n","Next, we import or read the dataset. Click here to download the breast cancer dataset used in this implementation.\n"," After reading the dataset, divide the dataset into concepts and targets. Store the concepts into X and\n"," targets into y.\n","\"\"\"\n","dataset = pd.read_csv('/content/drive/MyDrive/Iris.csv')\n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, -1].values\n","\"\"\"\n","Splitting the dataset into the Training set and Test set\n","Once the dataset is read into the memory, next, divide the dataset into two parts, training and\n","testing using the train_test_split function from sklearn.\n"," The test_size and random_state attributes are set to 0.25 and 0 respectively.\n"," You can change these attributes as per your requirements.\n","\"\"\"\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n","\n","#Feature Scaling\n","\"\"\"\n","Feature scaling is the process of converting the data into a min-max range. In this case,\n"," the standard scalar method is used.\n","\"\"\"\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\"\"\"\n","Training the Naive Bayes Classification model on the Training set\n","Once the dataset is scaled, next, the Naive Bayes classifier algorithm is used to create a model.\n","The GaussianNB function is imported from sklearn.naive_bayes library. The hyperparameters such as kernel,\n","and random_state to linear, and 0 respectively. The remaining hyperparameters of the support vector machine\n"," algorithm are set to default values.\n","\"\"\"\n","from sklearn.naive_bayes import GaussianNB\n","classifier = GaussianNB()\n","classifier.fit(X_train, y_train)\n","\n","#Naive Bayes classifier model\n","GaussianNB(priors=None, var_smoothing=1e-09)\n","\n","#Display the results (confusion matrix and accuracy)\n","\"\"\"\n","Here evaluation metrics such as confusion matrix and accuracy are used to evaluate the performance of\n","the model built using a decision tree classifier.\n","\"\"\"\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","y_pred = classifier.predict(X_test)\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","accuracy_score(y_test, y_pred)\n"]}]}